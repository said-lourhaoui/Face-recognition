{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d as mplot3d\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing 25 subjects from 68 in the CMU PIE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected subjects are :\n",
      " ['33' '22' '28' '16' '5' '21' '57' '41' '18' '47' '8' '63' '49' '46' '66'\n",
      " '24' '14' '38' '34' '62' '10' '54' '30' '67' '39']\n"
     ]
    }
   ],
   "source": [
    "PIE_subjects = os.listdir(\"PIE\")\n",
    "selected_subjects = np.random.choice(PIE_subjects, size = 25, replace = False)\n",
    "train_photos_path = []\n",
    "test_photos_path  = []\n",
    "for subject in selected_subjects:\n",
    "    subject_photos = os.listdir(\"PIE\"+\"/\"+subject)\n",
    "    subject_train  = np.random.choice(subject_photos, size = int(0.7*len(subject_photos)), replace=False)\n",
    "    subject_test   = np.setdiff1d(subject_photos, subject_train)\n",
    "    for photo in subject_train :\n",
    "        train_photos_path.append(\"PIE\"+'/'+subject+'/'+photo)\n",
    "    for photo in subject_test :\n",
    "        test_photos_path.append(\"PIE\"+'/'+subject+'/'+photo)\n",
    "\n",
    "train_photos_array =  np.array([plt.imread(photo) for photo in train_photos_path])\n",
    "test_photos_array =  np.array([plt.imread(photo) for photo in test_photos_path])\n",
    "print(\"The selected subjects are :\\n\", selected_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_photos_array\n",
    "Y_train = np.array([path.split('/')[-2] for path in train_photos_path])\n",
    "X_test  = test_photos_array\n",
    "Y_test  = np.array([path.split('/')[-2] for path in test_photos_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading my selfies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies = os.listdir(\"selfies\")\n",
    "selfies_path = []\n",
    "for selfie in selfies :\n",
    "    selfies_path.append(\"selfies\" + '/' + selfie)\n",
    "train_selfies_path = np.random.choice(selfies_path, size = 7, replace=False)\n",
    "test_selfies_path  = np.setdiff1d(selfies_path, train_selfies_path)\n",
    "\n",
    "#train_selfies_array = np.array([plt.imread(selfie) for selfie in train_selfies_name])\n",
    "#test_selfies_array = np.array([plt.imread(selfie) for selfie in test_selfies_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selfies = np.array([plt.imread(selfie) for selfie in train_selfies_path])\n",
    "X_test_selfies  = np.array([plt.imread(selfie) for selfie in test_selfies_path])\n",
    "\n",
    "Y_train_selfies = np.array([69 for i in range(7)])\n",
    "Y_test_selfies  = np.array([69 for i in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, img_size1, img_size2 = X_train.shape\n",
    "num_features = img_size1*img_size2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the selfies to X_Train, X_test and Y_train, Y_test\n",
    "X_train = np.concatenate((X_train, X_train_selfies), axis=0)\n",
    "X_test  = np.concatenate((X_test, X_test_selfies), axis=0)\n",
    "Y_train = np.concatenate((Y_train, Y_train_selfies), axis=0)\n",
    "Y_test  = np.concatenate((Y_test, Y_test_selfies), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,img_size1, img_size1, 1)\n",
    "X_test  = X_test.reshape(-1,img_size1, img_size1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The overall data\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "Y = np.concatenate((Y_train, Y_test), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Onehot encoding of the class vector\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "Y_train_bin    = onehot_encoder.fit_transform(Y_train.reshape(len(Y_train), 1))\n",
    "Y_test_bin     = onehot_encoder.fit_transform(Y_test.reshape(len(Y_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "# Initialize model\n",
    "model = Sequential()\n",
    "# conv_layer1\n",
    "model.add(Conv2D(filters=20, kernel_size=5, padding=\"same\", input_shape=(img_size1, img_size2, 1)))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# conv_layer2\n",
    "model.add(Conv2D(filters=50, kernel_size=5, padding='same'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# FC layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(26))\n",
    "model.add(Activation('softmax')) \n",
    "model.compile(optimizer=optimizers.Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 20)        520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 50)        25050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               1600500   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 26)                13026     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26)                0         \n",
      "=================================================================\n",
      "Total params: 1,639,096\n",
      "Trainable params: 1,639,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "30/30 [==============================] - 7s 250ms/step - loss: 0.1729 - accuracy: 0.9627 - val_loss: 0.3669 - val_accuracy: 0.8978\n",
      "Epoch 2/60\n",
      "30/30 [==============================] - 8s 252ms/step - loss: 0.1607 - accuracy: 0.9651 - val_loss: 0.3566 - val_accuracy: 0.8939\n",
      "Epoch 3/60\n",
      "30/30 [==============================] - 7s 239ms/step - loss: 0.1510 - accuracy: 0.9692 - val_loss: 0.3408 - val_accuracy: 0.9039\n",
      "Epoch 4/60\n",
      "30/30 [==============================] - 7s 250ms/step - loss: 0.1414 - accuracy: 0.9719 - val_loss: 0.3331 - val_accuracy: 0.9070\n",
      "Epoch 5/60\n",
      "30/30 [==============================] - 7s 239ms/step - loss: 0.1336 - accuracy: 0.9756 - val_loss: 0.3272 - val_accuracy: 0.9085\n",
      "Epoch 6/60\n",
      "30/30 [==============================] - 7s 241ms/step - loss: 0.1257 - accuracy: 0.9766 - val_loss: 0.3207 - val_accuracy: 0.9108\n",
      "Epoch 7/60\n",
      "30/30 [==============================] - 7s 235ms/step - loss: 0.1174 - accuracy: 0.9804 - val_loss: 0.3025 - val_accuracy: 0.9154\n",
      "Epoch 8/60\n",
      "30/30 [==============================] - 7s 241ms/step - loss: 0.1085 - accuracy: 0.9827 - val_loss: 0.2984 - val_accuracy: 0.9178\n",
      "Epoch 9/60\n",
      "30/30 [==============================] - 8s 264ms/step - loss: 0.1049 - accuracy: 0.9824 - val_loss: 0.2935 - val_accuracy: 0.9170\n",
      "Epoch 10/60\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 0.0997 - accuracy: 0.9844 - val_loss: 0.2833 - val_accuracy: 0.9193\n",
      "Epoch 11/60\n",
      "30/30 [==============================] - 9s 288ms/step - loss: 0.0939 - accuracy: 0.9854 - val_loss: 0.2774 - val_accuracy: 0.9224\n",
      "Epoch 12/60\n",
      "30/30 [==============================] - 9s 307ms/step - loss: 0.0881 - accuracy: 0.9878 - val_loss: 0.2702 - val_accuracy: 0.9293\n",
      "Epoch 13/60\n",
      "30/30 [==============================] - 9s 296ms/step - loss: 0.0841 - accuracy: 0.9895 - val_loss: 0.2635 - val_accuracy: 0.9239\n",
      "Epoch 14/60\n",
      "30/30 [==============================] - 10s 335ms/step - loss: 0.0788 - accuracy: 0.9912 - val_loss: 0.2597 - val_accuracy: 0.9247\n",
      "Epoch 15/60\n",
      "30/30 [==============================] - 8s 281ms/step - loss: 0.0759 - accuracy: 0.9912 - val_loss: 0.2509 - val_accuracy: 0.9301\n",
      "Epoch 16/60\n",
      "30/30 [==============================] - 8s 280ms/step - loss: 0.0723 - accuracy: 0.9905 - val_loss: 0.2452 - val_accuracy: 0.9324\n",
      "Epoch 17/60\n",
      "30/30 [==============================] - 8s 255ms/step - loss: 0.0687 - accuracy: 0.9922 - val_loss: 0.2423 - val_accuracy: 0.9370\n",
      "Epoch 18/60\n",
      "30/30 [==============================] - 9s 295ms/step - loss: 0.0650 - accuracy: 0.9922 - val_loss: 0.2360 - val_accuracy: 0.9362\n",
      "Epoch 19/60\n",
      "30/30 [==============================] - 8s 275ms/step - loss: 0.0628 - accuracy: 0.9925 - val_loss: 0.2297 - val_accuracy: 0.9385\n",
      "Epoch 20/60\n",
      "30/30 [==============================] - 9s 293ms/step - loss: 0.0595 - accuracy: 0.9932 - val_loss: 0.2277 - val_accuracy: 0.9385\n",
      "Epoch 21/60\n",
      "30/30 [==============================] - 8s 273ms/step - loss: 0.0568 - accuracy: 0.9939 - val_loss: 0.2212 - val_accuracy: 0.9439\n",
      "Epoch 22/60\n",
      "30/30 [==============================] - 9s 286ms/step - loss: 0.0538 - accuracy: 0.9949 - val_loss: 0.2204 - val_accuracy: 0.9431\n",
      "Epoch 23/60\n",
      "30/30 [==============================] - 10s 326ms/step - loss: 0.0521 - accuracy: 0.9946 - val_loss: 0.2211 - val_accuracy: 0.9431\n",
      "Epoch 24/60\n",
      "30/30 [==============================] - 12s 391ms/step - loss: 0.0500 - accuracy: 0.9956 - val_loss: 0.2129 - val_accuracy: 0.9462\n",
      "Epoch 25/60\n",
      "30/30 [==============================] - 9s 285ms/step - loss: 0.0481 - accuracy: 0.9970 - val_loss: 0.2177 - val_accuracy: 0.9439\n",
      "Epoch 26/60\n",
      "30/30 [==============================] - 8s 274ms/step - loss: 0.0458 - accuracy: 0.9963 - val_loss: 0.2068 - val_accuracy: 0.9470\n",
      "Epoch 27/60\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 0.0442 - accuracy: 0.9973 - val_loss: 0.2020 - val_accuracy: 0.9523\n",
      "Epoch 28/60\n",
      "30/30 [==============================] - 9s 294ms/step - loss: 0.0420 - accuracy: 0.9970 - val_loss: 0.2030 - val_accuracy: 0.9477\n",
      "Epoch 29/60\n",
      "30/30 [==============================] - 8s 276ms/step - loss: 0.0404 - accuracy: 0.9976 - val_loss: 0.1981 - val_accuracy: 0.9516\n",
      "Epoch 30/60\n",
      "30/30 [==============================] - 9s 311ms/step - loss: 0.0390 - accuracy: 0.9976 - val_loss: 0.1958 - val_accuracy: 0.9516\n",
      "Epoch 31/60\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 0.0379 - accuracy: 0.9980 - val_loss: 0.1942 - val_accuracy: 0.9493\n",
      "Epoch 32/60\n",
      "30/30 [==============================] - 8s 282ms/step - loss: 0.0360 - accuracy: 0.9983 - val_loss: 0.1918 - val_accuracy: 0.9508\n",
      "Epoch 33/60\n",
      "30/30 [==============================] - 8s 250ms/step - loss: 0.0349 - accuracy: 0.9976 - val_loss: 0.1851 - val_accuracy: 0.9539\n",
      "Epoch 34/60\n",
      "30/30 [==============================] - 8s 278ms/step - loss: 0.0332 - accuracy: 0.9983 - val_loss: 0.1867 - val_accuracy: 0.9554\n",
      "Epoch 35/60\n",
      "30/30 [==============================] - 8s 254ms/step - loss: 0.0321 - accuracy: 0.9980 - val_loss: 0.1842 - val_accuracy: 0.9554\n",
      "Epoch 36/60\n",
      "30/30 [==============================] - 8s 270ms/step - loss: 0.0303 - accuracy: 0.9986 - val_loss: 0.1818 - val_accuracy: 0.9562\n",
      "Epoch 37/60\n",
      "30/30 [==============================] - 8s 256ms/step - loss: 0.0299 - accuracy: 0.9980 - val_loss: 0.1804 - val_accuracy: 0.9577\n",
      "Epoch 38/60\n",
      "30/30 [==============================] - 8s 264ms/step - loss: 0.0283 - accuracy: 0.9986 - val_loss: 0.1792 - val_accuracy: 0.9554\n",
      "Epoch 39/60\n",
      "30/30 [==============================] - 8s 271ms/step - loss: 0.0277 - accuracy: 0.9983 - val_loss: 0.1753 - val_accuracy: 0.9585\n",
      "Epoch 40/60\n",
      "30/30 [==============================] - 8s 255ms/step - loss: 0.0267 - accuracy: 0.9986 - val_loss: 0.1722 - val_accuracy: 0.9577\n",
      "Epoch 41/60\n",
      "30/30 [==============================] - 7s 248ms/step - loss: 0.0260 - accuracy: 0.9983 - val_loss: 0.1707 - val_accuracy: 0.9585\n",
      "Epoch 42/60\n",
      "30/30 [==============================] - 8s 259ms/step - loss: 0.0245 - accuracy: 0.9986 - val_loss: 0.1697 - val_accuracy: 0.9570\n",
      "Epoch 43/60\n",
      "30/30 [==============================] - 8s 264ms/step - loss: 0.0237 - accuracy: 0.9986 - val_loss: 0.1692 - val_accuracy: 0.9585\n",
      "Epoch 44/60\n",
      "30/30 [==============================] - 8s 265ms/step - loss: 0.0228 - accuracy: 0.9983 - val_loss: 0.1673 - val_accuracy: 0.9600\n",
      "Epoch 45/60\n",
      "30/30 [==============================] - 8s 254ms/step - loss: 0.0220 - accuracy: 0.9997 - val_loss: 0.1648 - val_accuracy: 0.9585\n",
      "Epoch 46/60\n",
      "30/30 [==============================] - 8s 253ms/step - loss: 0.0214 - accuracy: 0.9990 - val_loss: 0.1640 - val_accuracy: 0.9608\n",
      "Epoch 47/60\n",
      "30/30 [==============================] - 9s 286ms/step - loss: 0.0208 - accuracy: 0.9993 - val_loss: 0.1614 - val_accuracy: 0.9616\n",
      "Epoch 48/60\n",
      "30/30 [==============================] - 7s 238ms/step - loss: 0.0200 - accuracy: 0.9997 - val_loss: 0.1589 - val_accuracy: 0.9608\n",
      "Epoch 49/60\n",
      "30/30 [==============================] - 7s 232ms/step - loss: 0.0200 - accuracy: 0.9990 - val_loss: 0.1581 - val_accuracy: 0.9616\n",
      "Epoch 50/60\n",
      "30/30 [==============================] - 7s 238ms/step - loss: 0.0188 - accuracy: 0.9997 - val_loss: 0.1571 - val_accuracy: 0.9616\n",
      "Epoch 51/60\n",
      "30/30 [==============================] - 7s 238ms/step - loss: 0.0179 - accuracy: 0.9997 - val_loss: 0.1554 - val_accuracy: 0.9639\n",
      "Epoch 52/60\n",
      "30/30 [==============================] - 7s 243ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9631\n",
      "Epoch 53/60\n",
      "30/30 [==============================] - 7s 240ms/step - loss: 0.0169 - accuracy: 0.9997 - val_loss: 0.1547 - val_accuracy: 0.9639\n",
      "Epoch 54/60\n",
      "30/30 [==============================] - 7s 241ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9639\n",
      "Epoch 55/60\n",
      "30/30 [==============================] - 7s 247ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9623\n",
      "Epoch 56/60\n",
      "30/30 [==============================] - 7s 235ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.9623\n",
      "Epoch 57/60\n",
      "30/30 [==============================] - 7s 240ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9623\n",
      "Epoch 58/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 7s 240ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9654\n",
      "Epoch 59/60\n",
      "30/30 [==============================] - 7s 249ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9646\n",
      "Epoch 60/60\n",
      "30/30 [==============================] - 7s 244ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15a9d330250>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X_train, Y_train_bin, epochs=60, batch_size=100, validation_data=(X_test, Y_test_bin),\n",
    "              shuffle=True, verbose=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 2s 24ms/step - loss: 0.0129 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "training_loss, training_acc = model.evaluate(X_train, Y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1453 - accuracy: 0.9646\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, Y_test_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
